"""
dt_enrichment.py  â€”  Drive-Test Spatial Enrichment
===================================================
EXACT port of the original standalone enrichment script.

Original script logic (copied exactly):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
for site_id, site_preds in pred_df.groupby("site_id"):
    valid_nodes = site_df[site_df["site_id"] == site_id]["nodeb_id"].unique()
    site_dt = dt_df[dt_df["nodeb_id"].isin(valid_nodes)].copy()
    
    tree = BallTree(dt_coords, metric='haversine')
    k_neighbors = min(3, len(site_dt))
    distances, indices = tree.query(pred_coords, k=k_neighbors)
    distances_m = distances * 6371000
    
    for i, orig_index in enumerate(site_preds.index):
        valid_mask = distances_m[i] <= MAX_DISTANCE_METERS
        if np.sum(valid_mask) == 0: continue
        valid_rsrp = site_dt.iloc[idxs[valid_mask]]["rsrp"].values
        if len(valid_rsrp) >= 2: top2_avg = mean(valid_rsrp[:2])
        if len(valid_rsrp) >= 3: top3_avg = mean(valid_rsrp[:3])

Key differences from previous version:
  â€¢ Uses site_dt.iloc[indices[valid_mask]] â€” positional indexing, requires reset_index()
  â€¢ k_neighbors = min(3, len(site_dt)) â€” hardcoded 3, not max(top_n_values)
  â€¢ measured_dt_rsrp = valid_rsrp[0] (nearest single point) â€” kept for DB schema
  â€¢ top2_avg only written if >= 2 valid points (same as original)
  â€¢ top3_avg only written if >= 3 valid points (same as original)
  â€¢ NO top2 written for single-match pixels (matches original exactly)
"""

from __future__ import annotations

import numpy as np
import pandas as pd
from sklearn.neighbors import BallTree

EARTH_RADIUS_M  = 6_371_000.0
MAX_DISTANCE_M  = 25.0          # fixed â€” matches original MAX_DISTANCE_METERS = 25


def enrich_predictions(
    pred_df:         pd.DataFrame,
    dt_df:           pd.DataFrame,
    site_mapping_df: pd.DataFrame,
    max_distance_m:  float = 25.0,
    top_n_values:    tuple[int, ...] = (2, 3),
) -> pd.DataFrame:
    """
    Parameters
    ----------
    pred_df         : Pass-1 grid  â€” needs lat, lon, site_id
    dt_df           : merged DT logs â€” needs lat, lon, rsrp, nodeb_id
    site_mapping_df : site_id â†’ nodeb_id mapping  (from site_prediction table)
    max_distance_m  : BallTree match radius in metres (default 25 â€” matches original)
    top_n_values    : which top-N averages to compute (default (2, 3))

    Returns
    -------
    pred_df with added columns:
        pred_rsrp_top2_avg   â€” mean RSRP of nearest 2 DT points within radius
        pred_rsrp_top3_avg   â€” mean RSRP of nearest 3 DT points within radius
        measured_dt_rsrp     â€” RSRP of single nearest DT point (added for DB schema)

    Pixels with no DT match within radius keep NaN.
    Only written if enough neighbours exist (top2 needs â‰¥2, top3 needs â‰¥3).
    """
    # â”€â”€ Normalize column names â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    pred_df         = _normcols(pred_df.copy())
    dt_df           = _normcols(dt_df.copy())
    site_mapping_df = _normcols(site_mapping_df.copy())

    _require(pred_df,         ["lat", "lon", "site_id"],          "pred_df")
    _require(dt_df,           ["lat", "lon", "rsrp", "nodeb_id"], "dt_df")
    _require(site_mapping_df, ["site_id", "nodeb_id"],            "site_mapping_df")

    # â”€â”€ Cast all join keys to str â€” prevents type-mismatch silent failures â”€â”€â”€
    pred_df["site_id"]          = pred_df["site_id"].astype(str)
    dt_df["nodeb_id"]           = dt_df["nodeb_id"].astype(str)
    site_mapping_df["site_id"]  = site_mapping_df["site_id"].astype(str)
    site_mapping_df["nodeb_id"] = site_mapping_df["nodeb_id"].astype(str)

    # â”€â”€ Clean DT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    dt_df = dt_df.dropna(subset=["lat", "lon", "rsrp", "nodeb_id"])
    dt_df["rsrp"] = pd.to_numeric(dt_df["rsrp"], errors="coerce")
    dt_df = dt_df.dropna(subset=["rsrp"])

    if dt_df.empty:
        print("âš  dt_enrichment: no valid DT rows â€” enrichment skipped.")
        # Still initialise output columns
        for n in top_n_values:
            pred_df[f"pred_rsrp_top{n}_avg"] = np.nan
        pred_df["measured_dt_rsrp"] = np.nan
        return pred_df

    print(f"\nğŸ” DT Enrichment â€” {len(dt_df):,} DT rows | "
          f"radius={max_distance_m} m | top_n={top_n_values}")

    # â”€â”€ Initialise output columns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    for n in top_n_values:
        pred_df[f"pred_rsrp_top{n}_avg"] = np.nan
    pred_df["measured_dt_rsrp"] = np.nan

    enriched = 0

    for site_id, site_preds in pred_df.groupby("site_id"):

        # â”€â”€ site_id â†’ valid nodeb_id(s) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        valid_nodes = site_mapping_df.loc[
            site_mapping_df["site_id"] == site_id, "nodeb_id"
        ].unique()

        if len(valid_nodes) == 0:
            print(f"   âš  No nodeb_id mapping for site_id={site_id} â€” skipped.")
            continue

        # â”€â”€ Filter DT to this site's NodeBs only â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        site_dt = dt_df[dt_df["nodeb_id"].isin(valid_nodes)].copy()

        if site_dt.empty:
            continue

        # â”€â”€ CRITICAL: reset_index so iloc[...] positional indexing is safe â”€â”€â”€
        # Original: site_dt.iloc[idxs[valid_mask]] â€” requires 0-based integer index
        # Without reset_index(), iloc positions and BallTree positions can diverge
        site_dt = site_dt.reset_index(drop=True)

        # â”€â”€ Build BallTree â€” haversine needs radians â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        dt_coords   = np.radians(site_dt[["lat", "lon"]].values)
        pred_coords = np.radians(site_preds[["lat", "lon"]].values)

        # k_neighbors = min(3, len(site_dt)) â€” exact from original
        k_neighbors = min(3, len(site_dt))
        tree = BallTree(dt_coords, metric="haversine")
        dist_rad, indices = tree.query(pred_coords, k=k_neighbors)
        dist_m = dist_rad * EARTH_RADIUS_M   # convert radians â†’ metres

        # â”€â”€ Per-pixel matching â€” exact logic from original â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        for i, orig_idx in enumerate(site_preds.index):
            dists = dist_m[i]
            idxs  = indices[i]

            valid_mask = dists <= max_distance_m

            if np.sum(valid_mask) == 0:
                continue

            # site_dt.iloc[idxs[valid_mask]] â€” exact from original
            valid_rsrp = site_dt.iloc[idxs[valid_mask]]["rsrp"].values
            enriched  += 1

            # Nearest single DT point (for DB schema â€” not in original script)
            pred_df.at[orig_idx, "measured_dt_rsrp"] = float(valid_rsrp[0])

            # Top2 â€” only if >= 2 valid points (exact from original)
            if len(valid_rsrp) >= 2:
                pred_df.at[orig_idx, "pred_rsrp_top2_avg"] = float(
                    np.mean(valid_rsrp[:2])
                )

            # Top3 â€” only if >= 3 valid points (exact from original)
            if len(valid_rsrp) >= 3:
                pred_df.at[orig_idx, "pred_rsrp_top3_avg"] = float(
                    np.mean(valid_rsrp[:3])
                )

    pct = enriched / len(pred_df) * 100 if len(pred_df) else 0.0
    print(f"   âœ… {enriched:,}/{len(pred_df):,} pixels enriched ({pct:.1f}%)")
    return pred_df


# â”€â”€ helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _normcols(df: pd.DataFrame) -> pd.DataFrame:
    """Normalize column names: strip, lowercase, spacesâ†’underscore."""
    df.columns = df.columns.str.strip().str.lower().str.replace(" ", "_")
    return df


def _require(df: pd.DataFrame, cols: list[str], name: str):
    missing = [c for c in cols if c not in df.columns]
    if missing:
        raise ValueError(
            f"dt_enrichment '{name}' missing required columns: {missing}. "
            f"Got: {df.columns.tolist()}"
        )